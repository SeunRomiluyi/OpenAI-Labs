{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Managing conversation history with the ChatGPT model\n",
    "This sample notebook demonstrates a couple of simple patterns you can use for managing the prompts and conversation history with the ChatGPT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DOCKER_BUILDKIT': '1',\n",
       " 'ENABLE_DYNAMIC_INSTALL': 'true',\n",
       " 'LESSOPEN': '| /usr/bin/lesspipe %s',\n",
       " 'GITHUB_TOKEN': '<hidden>',\n",
       " 'PYTHONIOENCODING': 'UTF-8',\n",
       " 'GITHUB_CODESPACE_TOKEN': '<hidden>',\n",
       " 'USER': 'codespace',\n",
       " 'RVM_PATH': '/usr/local/rvm',\n",
       " 'NVS_ROOT': '/usr/local/nvs',\n",
       " 'HOSTNAME': 'codespaces-3f0539',\n",
       " 'PIPX_HOME': '/usr/local/py-utils',\n",
       " 'CONDA_SCRIPT': '/opt/conda/etc/profile.d/conda.sh',\n",
       " 'SHLVL': '1',\n",
       " 'GITHUB_CODESPACES_PORT_FORWARDING_DOMAIN': 'preview.app.github.dev',\n",
       " 'HUGO_ROOT': '/home/codespace/.hugo',\n",
       " 'HOME': '/home/codespace',\n",
       " 'OLDPWD': '/',\n",
       " 'ORYX_ENV_TYPE': 'vsonline-present',\n",
       " 'NVM_BIN': '/usr/local/share/nvm/versions/node/v19.9.0/bin',\n",
       " 'CODESPACES': 'true',\n",
       " 'NVM_SYMLINK_CURRENT': 'true',\n",
       " 'PIPX_BIN_DIR': '/usr/local/py-utils/bin',\n",
       " 'DYNAMIC_INSTALL_ROOT_DIR': '/opt',\n",
       " 'NVM_INC': '/usr/local/share/nvm/versions/node/v19.9.0/include/node',\n",
       " 'rvm_stored_umask': '0022',\n",
       " 'ORYX_DIR': '/usr/local/oryx',\n",
       " 'GRADLE_HOME': '/usr/local/sdkman/candidates/gradle/current',\n",
       " 'JUPYTERLAB_PATH': '/home/codespace/.local/bin',\n",
       " 'rvm_user_install_flag': '0',\n",
       " 'MAVEN_HOME': '/usr/local/sdkman/candidates/maven/current',\n",
       " 'GOROOT': '/usr/local/go',\n",
       " 'NODE_ROOT': '/home/codespace/nvm',\n",
       " 'GITHUB_GRAPHQL_URL': 'https://api.github.com/graphql',\n",
       " 'GITHUB_USER': 'pragmatical',\n",
       " 'NVM_DIR': '/usr/local/share/nvm',\n",
       " 'PYTHON_PATH': '/usr/local/python/current',\n",
       " 'DOTNET_SKIP_FIRST_TIME_EXPERIENCE': '1',\n",
       " 'ContainerVersion': '13',\n",
       " 'NVS_HOME': '/usr/local/nvs',\n",
       " 'GITHUB_API_URL': 'https://api.github.com',\n",
       " 'RepositoryName': 'OpenAI-Labs',\n",
       " 'rvm_bin_path': '/usr/local/rvm/bin',\n",
       " 'SDKMAN_CANDIDATES_API': 'https://api.sdkman.io/2',\n",
       " '_': '/usr/bin/cat',\n",
       " 'RUBY_VERSION': 'ruby-3.1.4',\n",
       " 'PROMPT_DIRTRIM': '4',\n",
       " 'IRBRC': '/usr/local/rvm/rubies/ruby-3.1.4/.irbrc',\n",
       " 'CLOUDENV_ENVIRONMENT_ID': 'e90021ae-2b98-4760-b788-e3369f4b47d2',\n",
       " 'DOTNET_ROOT': '/usr/local/dotnet/current',\n",
       " 'NVS_DIR': '/usr/local/nvs',\n",
       " 'PHP_ROOT': '/home/codespace/.php',\n",
       " 'PATH': '/home/codespace/.python/current/bin:/vscode/bin/linux-x64/b3e4e68a0bc097f0ae7907b217c1119af9e03435/bin/remote-cli:/home/codespace/.local/bin:/home/codespace/.dotnet:/home/codespace/nvm/current/bin:/home/codespace/.php/current/bin:/home/codespace/.python/current/bin:/home/codespace/java/current/bin:/home/codespace/.ruby/current/bin:/home/codespace/.local/bin:/usr/local/oryx:/usr/local/go/bin:/go/bin:/usr/local/sdkman/bin:/usr/local/sdkman/candidates/java/current/bin:/usr/local/sdkman/candidates/gradle/current/bin:/usr/local/sdkman/candidates/maven/current/bin:/usr/local/sdkman/candidates/ant/current/bin:/usr/local/rvm/gems/default/bin:/usr/local/rvm/gems/default@global/bin:/usr/local/rvm/rubies/default/bin:/usr/local/share/rbenv/bin:/opt/conda/bin:/usr/local/php/current/bin:/usr/local/python/current/bin:/usr/local/py-utils/bin:/usr/local/nvs:/usr/local/share/nvm/current/bin:/usr/local/hugo/bin:/usr/local/dotnet/current:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/rvm/bin:/vscode/bin/linux-x64/b3e4e68a0bc097f0ae7907b217c1119af9e03435/bin/remote-cli:/home/codespace/.local/bin:/home/codespace/.dotnet:/home/codespace/nvm/current/bin:/home/codespace/.php/current/bin:/home/codespace/.python/current/bin:/home/codespace/java/current/bin:/home/codespace/.ruby/current/bin:/home/codespace/.local/bin:/usr/local/oryx:/usr/local/go/bin:/go/bin:/usr/local/sdkman/bin:/usr/local/sdkman/candidates/java/current/bin:/usr/local/sdkman/candidates/gradle/current/bin:/usr/local/sdkman/candidates/maven/current/bin:/usr/local/sdkman/candidates/ant/current/bin:/usr/local/rvm/gems/default/bin:/usr/local/rvm/gems/default@global/bin:/usr/local/rvm/rubies/default/bin:/usr/local/share/rbenv/bin:/opt/conda/bin:/usr/local/php/current/bin:/usr/local/python/current/bin:/usr/local/py-utils/bin:/usr/local/nvs:/usr/local/share/nvm/current/bin:/usr/local/hugo/bin:/usr/local/dotnet/current:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/rvm/bin',\n",
       " 'JAVA_ROOT': '/home/codespace/java',\n",
       " 'VSCODE_AGENT_FOLDER': '/home/codespace/.vscode-remote',\n",
       " 'SDKMAN_CANDIDATES_DIR': '/usr/local/sdkman/candidates',\n",
       " 'HUGO_DIR': '/usr/local/hugo/bin',\n",
       " 'NPM_GLOBAL': '/home/codespace/.npm-global',\n",
       " 'SHELL_LOGGED_IN': 'true',\n",
       " 'MY_RUBY_HOME': '/usr/local/rvm/rubies/ruby-3.1.4',\n",
       " 'LANG': 'C.UTF-8',\n",
       " 'SDKMAN_DIR': '/usr/local/sdkman',\n",
       " 'RUBY_ROOT': '/home/codespace/.ruby',\n",
       " 'LS_COLORS': '',\n",
       " 'SDKMAN_PLATFORM': 'linuxx64',\n",
       " 'GITHUB_REPOSITORY': 'retaildevcrews/OpenAI-Labs',\n",
       " 'SHELL': '/bin/bash',\n",
       " 'GOPATH': '/go',\n",
       " 'rvm_prefix': '/usr/local',\n",
       " 'rvm_loaded_flag': '1',\n",
       " 'GEM_HOME': '/usr/local/rvm/gems/ruby-3.1.4',\n",
       " 'ORYX_PREFER_USER_INSTALLED_SDKS': 'true',\n",
       " 'LESSCLOSE': '/usr/bin/lesspipe %s %s',\n",
       " 'ORYX_SDK_STORAGE_BASE_URL': 'https://oryx-cdn.microsoft.io',\n",
       " 'CONDA_DIR': '/opt/conda',\n",
       " 'rvm_version': '1.29.12 (latest)',\n",
       " 'DEBIAN_FLAVOR': 'focal-scm',\n",
       " 'GEM_PATH': '/usr/local/rvm/gems/ruby-3.1.4:/usr/local/rvm/gems/ruby-3.1.4@global',\n",
       " 'JAVA_HOME': '/usr/local/sdkman/candidates/java/current',\n",
       " 'NVS_USE_XZ': '1',\n",
       " 'INTERNAL_VSCS_TARGET_URL': 'https://westus3.online.visualstudio.com',\n",
       " 'PWD': '/vscode/bin/linux-x64/b3e4e68a0bc097f0ae7907b217c1119af9e03435',\n",
       " 'NVM_CD_FLAGS': '',\n",
       " 'GITHUB_SERVER_URL': 'https://github.com',\n",
       " 'PHP_PATH': '/usr/local/php/current',\n",
       " 'PYTHON_ROOT': '/home/codespace/.python',\n",
       " 'RAILS_DEVELOPMENT_HOSTS': '.githubpreview.dev,.preview.app.github.dev,.app.github.dev',\n",
       " 'NVS_OS': 'linux',\n",
       " 'CODESPACE_NAME': 'pragmatical-obscure-yodel-p7p6r4xj737666',\n",
       " 'RUBY_HOME': '/usr/local/rvm/rubies/default',\n",
       " 'MAVEN_ROOT': '/home/codespace/.maven',\n",
       " 'rvm_path': '/usr/local/rvm',\n",
       " 'NUGET_XMLDOC_MODE': 'skip',\n",
       " 'VSCODE_HANDLES_SIGPIPE': 'true',\n",
       " 'VSCODE_AMD_ENTRYPOINT': 'vs/workbench/api/node/extensionHostProcess',\n",
       " 'VSCODE_HANDLES_UNCAUGHT_ERRORS': 'true',\n",
       " 'VSCODE_NLS_CONFIG': '{\"locale\":\"en\",\"osLocale\":\"en\",\"availableLanguages\":{}}',\n",
       " 'BROWSER': '/vscode/bin/linux-x64/b3e4e68a0bc097f0ae7907b217c1119af9e03435/bin/helpers/browser.sh',\n",
       " 'VSCODE_CWD': '/vscode/bin/linux-x64/b3e4e68a0bc097f0ae7907b217c1119af9e03435',\n",
       " 'ELECTRON_RUN_AS_NODE': '1',\n",
       " 'VSCODE_IPC_HOOK_CLI': '/tmp/vscode-ipc-fa5178db-4c22-4695-bba6-0e857c2f1824.sock',\n",
       " 'PYDEVD_IPYTHON_COMPATIBLE_DEBUGGING': '1',\n",
       " 'PYTHONUNBUFFERED': '1',\n",
       " 'PYDEVD_USE_FRAME_EVAL': 'NO',\n",
       " 'TERM': 'xterm-color',\n",
       " 'CLICOLOR': '1',\n",
       " 'FORCE_COLOR': '1',\n",
       " 'CLICOLOR_FORCE': '1',\n",
       " 'PAGER': 'cat',\n",
       " 'GIT_PAGER': 'cat',\n",
       " 'MPLBACKEND': 'module://matplotlib_inline.backend_inline',\n",
       " 'OPENAI_API_KEY': '<hidden>',\n",
       " 'CHATGPT_MODEL': 'gpt',\n",
       " 'OPENAI_API_BASE': 'https://jl-azure-openai-001.openai.azure.com/',\n",
       " 'OPENAI_API_VERSION': '2023-03-15-preview'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import os module & the OpenAI Python library for calling the OpenAI API\n",
    "# please make sure you have installed required libraries via pip install -r requirements.txt\n",
    "import os\n",
    "import openai\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "%env\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'function' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Load config values\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[39m# The base URL for your Azure OpenAI resource. e.g. \"https://<your resource name>.openai.azure.com\"\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m openai\u001b[39m.\u001b[39mapi_base \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39;49mgetenv[\u001b[39m\"\u001b[39;49m\u001b[39mNVM_BIN\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[1;32m      6\u001b[0m \u001b[39m# This is set to `azure`\u001b[39;00m\n\u001b[1;32m      7\u001b[0m openai\u001b[39m.\u001b[39mapi_type \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mazure\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'function' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# Load config values\n",
    "\n",
    "# The base URL for your Azure OpenAI resource. e.g. \"https://<your resource name>.openai.azure.com\"\n",
    "openai.api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "    \n",
    "# This is set to `azure`\n",
    "openai.api_type = \"azure\"\n",
    "\n",
    "# The API key for your Azure OpenAI resource.\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "\n",
    "# Setting up the deployment name\n",
    "chatgpt_model_name = os.getenv(\"CHATGPT_MODEL\")\n",
    "\n",
    "# Currently Chat Completions API have the following versions available: 2023-03-15-preview\n",
    "openai.api_version = os.getenv(\"OPENAI_API_VERSION\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 Create the system message for ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful assistant.... Not\n"
     ]
    }
   ],
   "source": [
    "base_system_message = \"You are a helpful assistant.... Not\"\n",
    "\n",
    "system_message = f\"{base_system_message.strip()}\"\n",
    "print(system_message)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 Define helper functions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "def num_tokens_from_messages(messages, model=\"gpt-3.5-turbo-0301\"):\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += 4  # every message follows <im_start>{role/name}\\n{content}<im_end>\\n\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":  # if there's a name, the role is omitted\n",
    "                num_tokens += -1  # role is always required and always 1 token\n",
    "    num_tokens += 2  # every reply is primed with <im_start>assistant\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to send the prompt to the ChatGPT model\n",
    "# More info : https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/chatgpt?pivots=programming-language-chat-completions\n",
    "def send_message(messages, model_name, max_response_tokens=500):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        engine=chatgpt_model_name,\n",
    "        messages=messages,\n",
    "        temperature=0.5,\n",
    "        max_tokens=max_response_tokens,\n",
    "        top_p=0.9,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "    )\n",
    "    return response['choices'][0]['message']['content']\n",
    "\n",
    "# Defining a function to print out the conversation in a readable format\n",
    "def print_conversation(messages):\n",
    "    for message in messages:\n",
    "        print(f\"[{message['role'].upper()}]\")\n",
    "        print(message['content'])\n",
    "        print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 Start the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the first user message that will be sent to the model. Feel free to update this.\n",
    "user_message = \"I want to write a blog post about the impact of AI on the future of work.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the list of messages. role can be either \"user\" or \"assistant\" \n",
    "messages=[\n",
    "    {\"role\": \"system\", \"content\": system_message},\n",
    "    {\"role\": \"user\", \"name\":\"example_user\", \"content\": user_message}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count: 38\n"
     ]
    }
   ],
   "source": [
    "token_count = num_tokens_from_messages(messages)\n",
    "print(f\"Token count: {token_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SYSTEM]\n",
      "You are a helpful assistant.... Not\n",
      "\n",
      "[USER]\n",
      "I want to write a blog post about the impact of AI on the future of work.\n",
      "\n",
      "[ASSISTANT]\n",
      "Great topic! Here are some points you could consider including in your post:\n",
      "\n",
      "1. Introduction to AI and its growing importance in the workplace\n",
      "2. Examples of AI technologies that are already impacting the workforce, such as chatbots, automation, and predictive analytics\n",
      "3. Benefits of AI for businesses, such as increased efficiency and productivity\n",
      "4. Concerns about the impact of AI on jobs and the workforce, including the potential for job displacement and the need for new skills and training\n",
      "5. Ways in which businesses and individuals can prepare for the future of work in an AI-driven world, such as upskilling and retraining\n",
      "6. Conclusion and thoughts on the future of work and AI\n",
      "\n",
      "Good luck with your blog post!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_response_tokens = 500\n",
    "\n",
    "response = send_message(messages, chatgpt_model_name, max_response_tokens)\n",
    "messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "\n",
    "print_conversation(messages)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0 Continue the conversation\n",
    "\n",
    "When working with the ChatGPT model, it's your responsibity to make sure you stay within the token limits of the model. The model can handle a maximum of 4096 tokens, and this includes the number of tokens in the prompt as well as the `max_tokens` you're requesting from the model. If you exceed these limits, the model will return an error.\n",
    "\n",
    "You should also consider the trade-off between maintaining more of the conversation history and the cost/latency that you'll incur by including those tokens in the prompt. Shorter prompts are cheaper and faster. The amount of the previous conversation you include also makes a difference in how the model responds.\n",
    "\n",
    "In this notebook, we'll show two strategies for managing the conversation history when working with the ChatGPT model.\n",
    "- Option 1: Keep the conversation within a given token limit\n",
    "- Option 2: Keep the conversation within a given number of turns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: Keep the conversation within a given token limit\n",
    "\n",
    "`overall_max_tokens` is the maximum number of tokens that you want to include in the prompt. Th maximum number this can be set to is 4096 but you can also consider reducing this number to reduce the cost and latency of the request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_max_tokens = 4096\n",
    "prompt_max_tokens = overall_max_tokens - max_response_tokens"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can continue the conversation below by editing the user_message and running the cell as many times as you would like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count: 212\n",
      "[SYSTEM]\n",
      "You are a helpful assistant.... Not\n",
      "\n",
      "[USER]\n",
      "I want to write a blog post about the impact of AI on the future of work.\n",
      "\n",
      "[ASSISTANT]\n",
      "Great topic! Here are some points you could consider including in your post:\n",
      "\n",
      "1. Introduction to AI and its growing importance in the workplace\n",
      "2. Examples of AI technologies that are already impacting the workforce, such as chatbots, automation, and predictive analytics\n",
      "3. Benefits of AI for businesses, such as increased efficiency and productivity\n",
      "4. Concerns about the impact of AI on jobs and the workforce, including the potential for job displacement and the need for new skills and training\n",
      "5. Ways in which businesses and individuals can prepare for the future of work in an AI-driven world, such as upskilling and retraining\n",
      "6. Conclusion and thoughts on the future of work and AI\n",
      "\n",
      "Good luck with your blog post!\n",
      "\n",
      "[USER]\n",
      "The target audience for the blog post should be business leaders working in the tech industry.\n",
      "\n",
      "[ASSISTANT]\n",
      "Great! In that case, you may want to tailor your blog post to address the specific concerns and challenges that business leaders in the tech industry may face when it comes to the impact of AI on the future of work. Here are some additional points you could consider including:\n",
      "\n",
      "1. The role of AI in driving innovation and competitiveness in the tech industry\n",
      "2. The potential for AI to transform business models and create new opportunities for growth and revenue\n",
      "3. The need for businesses to invest in AI and develop strategies for integrating it into their operations\n",
      "4. The importance of ethical considerations and responsible use of AI in the workplace, including issues such as bias and privacy\n",
      "5. The impact of AI on the skills and talent needed in the tech industry, and the need for businesses to invest in training and development programs for their employees\n",
      "6. Case studies or examples of businesses in the tech industry that are successfully leveraging AI to drive growth and innovation\n",
      "\n",
      "By tailoring your blog post to the concerns and interests of business leaders in the tech industry, you can make it more relevant and engaging for your target audience.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_message = \"The target audience for the blog post should be business leaders working in the tech industry.\"\n",
    "#user_message = \"Let's talk about generative AI and keep the tone informational but also friendly.\"\n",
    "#user_message = \"Show me a few more examples\"\n",
    "messages.append({\"role\": \"user\", \"content\": user_message})\n",
    "\n",
    "token_count = num_tokens_from_messages(messages)\n",
    "print(f\"Token count: {token_count}\")\n",
    "\n",
    "# remove first message while over the token limit\n",
    "while token_count > prompt_max_tokens:\n",
    "    messages.pop(0)\n",
    "    token_count = num_tokens_from_messages(messages)\n",
    "\n",
    "response = send_message(messages, chatgpt_model_name, max_response_tokens)\n",
    "\n",
    "messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "print_conversation(messages)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Keep the conversation within a given number of turns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_messages = 10\n",
    "\n",
    "overall_max_tokens = 4096\n",
    "prompt_max_tokens = overall_max_tokens - max_response_tokens"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can continue the conversation below by editing the user_message and running the cell as many times as you would like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SYSTEM]\n",
      "You are a helpful assistant.... Not\n",
      "\n",
      "[USER]\n",
      "I want to write a blog post about the impact of AI on the future of work.\n",
      "\n",
      "[ASSISTANT]\n",
      "Great topic! Here are some points you could consider including in your post:\n",
      "\n",
      "1. Introduction to AI and its growing importance in the workplace\n",
      "2. Examples of AI technologies that are already impacting the workforce, such as chatbots, automation, and predictive analytics\n",
      "3. Benefits of AI for businesses, such as increased efficiency and productivity\n",
      "4. Concerns about the impact of AI on jobs and the workforce, including the potential for job displacement and the need for new skills and training\n",
      "5. Ways in which businesses and individuals can prepare for the future of work in an AI-driven world, such as upskilling and retraining\n",
      "6. Conclusion and thoughts on the future of work and AI\n",
      "\n",
      "Good luck with your blog post!\n",
      "\n",
      "[USER]\n",
      "The target audience for the blog post should be business leaders working in the tech industry.\n",
      "\n",
      "[ASSISTANT]\n",
      "Great! In that case, you may want to tailor your blog post to address the specific concerns and challenges that business leaders in the tech industry may face when it comes to the impact of AI on the future of work. Here are some additional points you could consider including:\n",
      "\n",
      "1. The role of AI in driving innovation and competitiveness in the tech industry\n",
      "2. The potential for AI to transform business models and create new opportunities for growth and revenue\n",
      "3. The need for businesses to invest in AI and develop strategies for integrating it into their operations\n",
      "4. The importance of ethical considerations and responsible use of AI in the workplace, including issues such as bias and privacy\n",
      "5. The impact of AI on the skills and talent needed in the tech industry, and the need for businesses to invest in training and development programs for their employees\n",
      "6. Case studies or examples of businesses in the tech industry that are successfully leveraging AI to drive growth and innovation\n",
      "\n",
      "By tailoring your blog post to the concerns and interests of business leaders in the tech industry, you can make it more relevant and engaging for your target audience.\n",
      "\n",
      "[USER]\n",
      "Make the post about generative AI aimed at business leaders who have some knowledge of the technology.\n",
      "\n",
      "[ASSISTANT]\n",
      "Great! Here is an outline for a blog post on generative AI aimed at business leaders who have some knowledge of the technology:\n",
      "\n",
      "1. Introduction to generative AI and its potential applications in the business world, such as content creation, product design, and marketing\n",
      "2. Explanation of how generative AI works, including the use of neural networks and machine learning algorithms\n",
      "3. Benefits of generative AI for businesses, such as increased efficiency and productivity, improved customer engagement, and enhanced creativity\n",
      "4. Case studies or examples of businesses that are successfully leveraging generative AI, including how they are using the technology and the results they have achieved\n",
      "5. Challenges and concerns associated with generative AI, such as the potential for bias and the need for ethical considerations\n",
      "6. Strategies for integrating generative AI into business operations, including the need for skilled talent and the importance of data management\n",
      "7. Future trends and developments in generative AI, including the potential for new applications and advances in technology\n",
      "\n",
      "By focusing on generative AI and its potential applications in the business world, you can provide business leaders with valuable insights and information on how this technology can be used to drive growth and innovation. Additionally, by assuming some prior knowledge of the technology, you can dive deeper into the technical aspects of generative AI and provide more detailed information for your target audience.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_message = \"Make the post about generative AI aimed at business leaders who have some knowledge of the technology.\"\n",
    "messages.append({\"role\": \"user\", \"content\": user_message})\n",
    "\n",
    "while len(messages) > max_messages:\n",
    "    messages.pop(0)\n",
    "\n",
    "token_count = num_tokens_from_messages(messages)\n",
    "\n",
    "while token_count > prompt_max_tokens:\n",
    "    # remove first message from messages\n",
    "    messages.pop(0)\n",
    "    token_count = num_tokens_from_messages(messages)\n",
    "\n",
    "response = send_message(messages, chatgpt_model_name)\n",
    "messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "print_conversation(messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "fc180f703c9255d3d630e6d09ed4eb3355d27845db546035ce1b410f2bfa43b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
