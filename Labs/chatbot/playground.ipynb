{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Managing conversation history with the ChatGPT model\n",
    "This sample notebook demonstrates a couple of simple patterns you can use for managing the prompts and conversation history with the ChatGPT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: OPENAI_API_KEY='3fa9cc1420f14abbabd9382e5ae49634'\n"
     ]
    }
   ],
   "source": [
    "%env OPENAI_API_KEY=<YOUR KEY GOES HERE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /usr/local/python/3.10.4/lib/python3.10/site-packages (0.27.2)\n",
      "Collecting openai\n",
      "  Downloading openai-0.27.6-py3-none-any.whl (71 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.20 in /home/codespace/.local/lib/python3.10/site-packages (from openai) (2.28.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/python/3.10.4/lib/python3.10/site-packages (from openai) (4.64.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/python/3.10.4/lib/python3.10/site-packages (from openai) (3.8.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.20->openai) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.20->openai) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.20->openai) (2022.12.7)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/codespace/.local/lib/python3.10/site-packages (from aiohttp->openai) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/python/3.10.4/lib/python3.10/site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/python/3.10.4/lib/python3.10/site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/python/3.10.4/lib/python3.10/site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/python/3.10.4/lib/python3.10/site-packages (from aiohttp->openai) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/python/3.10.4/lib/python3.10/site-packages (from aiohttp->openai) (1.3.1)\n",
      "Installing collected packages: openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 0.27.2\n",
      "    Uninstalling openai-0.27.2:\n",
      "      Successfully uninstalled openai-0.27.2\n",
      "Successfully installed openai-0.27.6\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: jsonpointer==2.3 in /home/codespace/.local/lib/python3.10/site-packages (2.3)\n",
      "Requirement already satisfied: jsonschema==4.17.3 in /home/codespace/.local/lib/python3.10/site-packages (4.17.3)\n",
      "Collecting openai==0.27.2\n",
      "  Using cached openai-0.27.2-py3-none-any.whl (70 kB)\n",
      "Requirement already satisfied: tiktoken==0.3.1 in /usr/local/python/3.10.4/lib/python3.10/site-packages (0.3.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /home/codespace/.local/lib/python3.10/site-packages (from jsonschema==4.17.3) (23.1.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /home/codespace/.local/lib/python3.10/site-packages (from jsonschema==4.17.3) (0.19.3)\n",
      "Requirement already satisfied: requests>=2.20 in /home/codespace/.local/lib/python3.10/site-packages (from openai==0.27.2) (2.28.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/python/3.10.4/lib/python3.10/site-packages (from openai==0.27.2) (4.64.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/python/3.10.4/lib/python3.10/site-packages (from openai==0.27.2) (3.8.4)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/python/3.10.4/lib/python3.10/site-packages (from tiktoken==0.3.1) (2023.5.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.20->openai==0.27.2) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.20->openai==0.27.2) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.20->openai==0.27.2) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.20->openai==0.27.2) (2022.12.7)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/python/3.10.4/lib/python3.10/site-packages (from aiohttp->openai==0.27.2) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/python/3.10.4/lib/python3.10/site-packages (from aiohttp->openai==0.27.2) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/python/3.10.4/lib/python3.10/site-packages (from aiohttp->openai==0.27.2) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/python/3.10.4/lib/python3.10/site-packages (from aiohttp->openai==0.27.2) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/python/3.10.4/lib/python3.10/site-packages (from aiohttp->openai==0.27.2) (1.3.1)\n",
      "Installing collected packages: openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 0.27.6\n",
      "    Uninstalling openai-0.27.6:\n",
      "      Successfully uninstalled openai-0.27.6\n",
      "Successfully installed openai-0.27.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# if needed, install and/or upgrade to the latest version of the OpenAI Python library\n",
    "%pip install --upgrade openai\n",
    "%pip install jsonpointer==2.3 jsonschema==4.17.3 openai==0.27.2 tiktoken==0.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os module & the OpenAI Python library for calling the OpenAI API\n",
    "# please make sure you have installed required libraries via pip install -r requirements.txt\n",
    "import os\n",
    "import openai\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config values\n",
    "with open(r'config.json') as config_file:\n",
    "    config_details = json.load(config_file)\n",
    "    \n",
    "# Setting up the deployment name\n",
    "chatgpt_model_name = config_details['CHATGPT_MODEL'] \n",
    "\n",
    "# This is set to `azure`\n",
    "openai.api_type = \"azure\"\n",
    "\n",
    "# The API key for your Azure OpenAI resource.\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# The base URL for your Azure OpenAI resource. e.g. \"https://<your resource name>.openai.azure.com\"\n",
    "openai.api_base = config_details['OPENAI_API_BASE']\n",
    "\n",
    "# Currently Chat Completions API have the following versions available: 2023-03-15-preview\n",
    "openai.api_version = config_details['OPENAI_API_VERSION']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 Create the system message for ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful assistant.... Not\n"
     ]
    }
   ],
   "source": [
    "base_system_message = \"You are a helpful assistant.... Not\"\n",
    "\n",
    "system_message = f\"{base_system_message.strip()}\"\n",
    "print(system_message)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 Define helper functions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "def num_tokens_from_messages(messages, model=\"gpt-3.5-turbo-0301\"):\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += 4  # every message follows <im_start>{role/name}\\n{content}<im_end>\\n\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":  # if there's a name, the role is omitted\n",
    "                num_tokens += -1  # role is always required and always 1 token\n",
    "    num_tokens += 2  # every reply is primed with <im_start>assistant\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to send the prompt to the ChatGPT model\n",
    "# More info : https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/chatgpt?pivots=programming-language-chat-completions\n",
    "def send_message(messages, model_name, max_response_tokens=500):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        engine=chatgpt_model_name,\n",
    "        messages=messages,\n",
    "        temperature=0.5,\n",
    "        max_tokens=max_response_tokens,\n",
    "        top_p=0.9,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "    )\n",
    "    return response['choices'][0]['message']['content']\n",
    "\n",
    "# Defining a function to print out the conversation in a readable format\n",
    "def print_conversation(messages):\n",
    "    for message in messages:\n",
    "        print(f\"[{message['role'].upper()}]\")\n",
    "        print(message['content'])\n",
    "        print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 Start the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the first user message that will be sent to the model. Feel free to update this.\n",
    "user_message = \"I want to write a blog post about the impact of AI on the future of work.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the list of messages. role can be either \"user\" or \"assistant\" \n",
    "messages=[\n",
    "    {\"role\": \"system\", \"content\": system_message},\n",
    "    {\"role\": \"user\", \"name\":\"example_user\", \"content\": user_message}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count: 38\n"
     ]
    }
   ],
   "source": [
    "token_count = num_tokens_from_messages(messages)\n",
    "print(f\"Token count: {token_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SYSTEM]\n",
      "You are a helpful assistant.... Not\n",
      "\n",
      "[USER]\n",
      "I want to write a blog post about the impact of AI on the future of work.\n",
      "\n",
      "[ASSISTANT]\n",
      "Great topic! Here are some ideas to get you started:\n",
      "\n",
      "1. Introduction: Introduce the topic and explain why it is important to discuss the impact of AI on the future of work.\n",
      "\n",
      "2. The benefits of AI in the workplace: Discuss how AI can improve productivity, efficiency, and accuracy in various industries.\n",
      "\n",
      "3. The potential risks and challenges of AI: Address concerns about job displacement, ethical issues, and the need for re-skilling and up-skilling.\n",
      "\n",
      "4. The role of humans in a world with AI: Explore how humans can work alongside AI and the importance of developing skills that complement AI.\n",
      "\n",
      "5. The future of work: Predict how AI will continue to shape the workplace and what changes we can expect to see in the coming years.\n",
      "\n",
      "6. Conclusion: Sum up the main points of your post and offer some final thoughts on the impact of AI on the future of work.\n",
      "\n",
      "Remember to provide examples and statistics to support your arguments, and to engage with your readers by asking questions and encouraging discussion. Good luck with your post!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_response_tokens = 500\n",
    "\n",
    "response = send_message(messages, chatgpt_model_name, max_response_tokens)\n",
    "messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "\n",
    "print_conversation(messages)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0 Continue the conversation\n",
    "\n",
    "When working with the ChatGPT model, it's your responsibity to make sure you stay within the token limits of the model. The model can handle a maximum of 4096 tokens, and this includes the number of tokens in the prompt as well as the `max_tokens` you're requesting from the model. If you exceed these limits, the model will return an error.\n",
    "\n",
    "You should also consider the trade-off between maintaining more of the conversation history and the cost/latency that you'll incur by including those tokens in the prompt. Shorter prompts are cheaper and faster. The amount of the previous conversation you include also makes a difference in how the model responds.\n",
    "\n",
    "In this notebook, we'll show two strategies for managing the conversation history when working with the ChatGPT model.\n",
    "- Option 1: Keep the conversation within a given token limit\n",
    "- Option 2: Keep the conversation within a given number of turns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: Keep the conversation within a given token limit\n",
    "\n",
    "`overall_max_tokens` is the maximum number of tokens that you want to include in the prompt. Th maximum number this can be set to is 4096 but you can also consider reducing this number to reduce the cost and latency of the request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_max_tokens = 4096\n",
    "prompt_max_tokens = overall_max_tokens - max_response_tokens"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can continue the conversation below by editing the user_message and running the cell as many times as you would like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count: 275\n",
      "[SYSTEM]\n",
      "You are a helpful assistant.... Not\n",
      "\n",
      "[USER]\n",
      "I want to write a blog post about the impact of AI on the future of work.\n",
      "\n",
      "[ASSISTANT]\n",
      "Great topic! Here are some ideas to get you started:\n",
      "\n",
      "1. Introduction: Introduce the topic and explain why it is important to discuss the impact of AI on the future of work.\n",
      "\n",
      "2. The benefits of AI in the workplace: Discuss how AI can improve productivity, efficiency, and accuracy in various industries.\n",
      "\n",
      "3. The potential risks and challenges of AI: Address concerns about job displacement, ethical issues, and the need for re-skilling and up-skilling.\n",
      "\n",
      "4. The role of humans in a world with AI: Explore how humans can work alongside AI and the importance of developing skills that complement AI.\n",
      "\n",
      "5. The future of work: Predict how AI will continue to shape the workplace and what changes we can expect to see in the coming years.\n",
      "\n",
      "6. Conclusion: Sum up the main points of your post and offer some final thoughts on the impact of AI on the future of work.\n",
      "\n",
      "Remember to provide examples and statistics to support your arguments, and to engage with your readers by asking questions and encouraging discussion. Good luck with your post!\n",
      "\n",
      "[USER]\n",
      "The target audience for the blog post should be business leaders working in the tech industry.\n",
      "\n",
      "[ASSISTANT]\n",
      "Great! In that case, you may want to consider the following suggestions to tailor your blog post to business leaders working in the tech industry:\n",
      "\n",
      "1. Start with a brief overview of AI and its current state of development. This will help set the stage for your discussion of its impact on the future of work.\n",
      "\n",
      "2. Focus on the specific ways in which AI is already being used in the tech industry, and the potential for further growth in the coming years.\n",
      "\n",
      "3. Discuss the benefits of AI for businesses, such as improved efficiency, cost savings, and the ability to make data-driven decisions.\n",
      "\n",
      "4. Address concerns about job displacement and the need for re-skilling and up-skilling, and discuss ways in which businesses can help their employees adapt to the changing landscape.\n",
      "\n",
      "5. Offer insights into how businesses can prepare for a future in which AI plays an increasingly important role, such as investing in employee training, developing new products and services that leverage AI, and collaborating with other businesses to share best practices.\n",
      "\n",
      "6. Conclude with a call to action, encouraging business leaders to embrace AI as a tool for growth and innovation, while also being mindful of its potential impact on their employees and the broader society.\n",
      "\n",
      "Remember to use clear and concise language, and to provide concrete examples and case studies to support your arguments. Good luck with your post!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_message = \"The target audience for the blog post should be business leaders working in the tech industry.\"\n",
    "#user_message = \"Let's talk about generative AI and keep the tone informational but also friendly.\"\n",
    "#user_message = \"Show me a few more examples\"\n",
    "messages.append({\"role\": \"user\", \"content\": user_message})\n",
    "\n",
    "token_count = num_tokens_from_messages(messages)\n",
    "print(f\"Token count: {token_count}\")\n",
    "\n",
    "# remove first message while over the token limit\n",
    "while token_count > prompt_max_tokens:\n",
    "    messages.pop(0)\n",
    "    token_count = num_tokens_from_messages(messages)\n",
    "\n",
    "response = send_message(messages, chatgpt_model_name, max_response_tokens)\n",
    "\n",
    "messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "print_conversation(messages)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Keep the conversation within a given number of turns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_messages = 10\n",
    "\n",
    "overall_max_tokens = 4096\n",
    "prompt_max_tokens = overall_max_tokens - max_response_tokens"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can continue the conversation below by editing the user_message and running the cell as many times as you would like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SYSTEM]\n",
      "You are a helpful assistant.\n",
      "\n",
      "[USER]\n",
      "I want to write a blog post about the impact of AI on the future of work.\n",
      "\n",
      "[ASSISTANT]\n",
      "Great idea! Here are some tips to get you started:\n",
      "\n",
      "1. Define AI and explain how it works.\n",
      "2. Discuss the current state of AI in the workplace and give examples of how it is being used.\n",
      "3. Explore the potential impact of AI on jobs and industries.\n",
      "4. Consider the ethical implications of AI and how it should be regulated.\n",
      "5. Offer suggestions for how individuals and organizations can prepare for the future of work in an AI-driven world.\n",
      "\n",
      "Remember to back up your claims with research and data, and make sure to write in a clear and concise manner that is easy for your readers to understand. Good luck!\n",
      "\n",
      "[USER]\n",
      "The target audience for the blog post should be business leaders working in the tech industry.\n",
      "\n",
      "[ASSISTANT]\n",
      "Great! In that case, you may want to tailor your writing to this specific audience. Here are some additional tips to consider:\n",
      "\n",
      "1. Use industry-specific language and terminology that will be familiar to your target audience.\n",
      "2. Highlight the specific ways that AI is currently being used in the tech industry, and provide examples of successful implementations.\n",
      "3. Discuss the potential impact of AI on the tech industry, including how it may change the nature of work and create new opportunities.\n",
      "4. Address any concerns or challenges that business leaders in the tech industry may have about AI, such as ethical considerations, regulatory issues, or the potential for job displacement.\n",
      "5. Offer practical advice for how tech leaders can prepare for the future of work in an AI-driven world, such as investing in employee training and development, exploring new business models, or partnering with AI startups.\n",
      "\n",
      "By tailoring your writing to the specific needs and interests of your target audience, you can create a blog post that is engaging, informative, and relevant to the tech industry.\n",
      "\n",
      "[USER]\n",
      "Make the post about generative AI aimed at business leaders who have some knowledge of the technology.\n",
      "\n",
      "[ASSISTANT]\n",
      "Sure! Here are some tips for writing a blog post about generative AI aimed at business leaders who have some knowledge of the technology:\n",
      "\n",
      "1. Define generative AI and explain how it differs from other types of AI, such as supervised learning and reinforcement learning.\n",
      "2. Discuss the current state of generative AI in the tech industry and give examples of how it is being used, such as in natural language processing, image and video synthesis, and music composition.\n",
      "3. Explore the potential impact of generative AI on various industries, including how it may change the way businesses create and distribute content, design products, and interact with customers.\n",
      "4. Address any concerns or challenges that business leaders may have about generative AI, such as ethical considerations, regulatory issues, or the potential for bias or errors.\n",
      "5. Offer practical advice for how business leaders can leverage generative AI to drive innovation and growth, such as partnering with AI startups, investing in research and development, or hiring data scientists and machine learning experts.\n",
      "\n",
      "By tailoring your writing to business leaders who have some knowledge of generative AI, you can dive deeper into the technical aspects of the technology and provide more nuanced insights and examples. This can help your readers better understand the potential of generative AI and how it can be applied to their businesses.\n",
      "\n",
      "[USER]\n",
      "Make the post about generative AI aimed at business leaders who have some knowledge of the technology.\n",
      "\n",
      "[ASSISTANT]\n",
      "Sure! Here are some tips for writing a blog post about generative AI aimed at business leaders who have some knowledge of the technology:\n",
      "\n",
      "1. Define generative AI and explain how it differs from other types of AI, such as supervised learning and reinforcement learning.\n",
      "2. Discuss the current state of generative AI in the tech industry and give examples of how it is being used, such as in natural language processing, image and video synthesis, and music composition.\n",
      "3. Explore the potential impact of generative AI on various industries, including how it may change the way businesses create and distribute content, design products, and interact with customers.\n",
      "4. Address any concerns or challenges that business leaders may have about generative AI, such as ethical considerations, regulatory issues, or the potential for bias or errors.\n",
      "5. Offer practical advice for how business leaders can leverage generative AI to drive innovation and growth, such as partnering with AI startups, investing in research and development, or hiring data scientists and machine learning experts.\n",
      "\n",
      "By tailoring your writing to business leaders who have some knowledge of generative AI, you can dive deeper into the technical aspects of the technology and provide more nuanced insights and examples. This can help your readers better understand the potential of generative AI and how it can be applied to their businesses.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_message = \"Make the post about generative AI aimed at business leaders who have some knowledge of the technology.\"\n",
    "messages.append({\"role\": \"user\", \"content\": user_message})\n",
    "\n",
    "while len(messages) > max_messages:\n",
    "    messages.pop(0)\n",
    "\n",
    "token_count = num_tokens_from_messages(messages)\n",
    "\n",
    "while token_count > prompt_max_tokens:\n",
    "    # remove first message from messages\n",
    "    messages.pop(0)\n",
    "    token_count = num_tokens_from_messages(messages)\n",
    "\n",
    "response = send_message(messages, chatgpt_model_name)\n",
    "messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "print_conversation(messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "fc180f703c9255d3d630e6d09ed4eb3355d27845db546035ce1b410f2bfa43b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
