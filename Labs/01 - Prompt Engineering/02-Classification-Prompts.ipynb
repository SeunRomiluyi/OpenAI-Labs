{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Prompts ChatGPT\n",
    "This sample notebook demonstrates how the Chat Completion API responds to different prompt techniques when classifying text.  Prompt Engineering material can be found here: \n",
    "(https://www.promptingguide.ai)\n",
    "\n",
    "For these examples we will show different prompt techniques while classifying text based on sentiment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os module & the OpenAI Python library for calling the OpenAI API\n",
    "# please make sure you have installed required libraries via pip install -r requirements.txt\n",
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config values\n",
    "\n",
    "# The base URL for your Azure OpenAI resource. e.g. \"https://<your resource name>.openai.azure.com\"\n",
    "openai.api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "    \n",
    "# This is set to `azure`\n",
    "openai.api_type = \"azure\"\n",
    "\n",
    "# The API key for your Azure OpenAI resource.\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Setting up the deployment name\n",
    "chatgpt_model_name = os.getenv(\"CHATGPT_MODEL\")\n",
    "\n",
    "# Currently Chat Completions API have the following versions available: 2023-03-15-preview\n",
    "openai.api_version = os.getenv(\"OPENAI_API_VERSION\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 Define Request to OpenAI API\n",
    "For these labs we are using the Azure OpenAI Completion API, this is different than the Chat completion API.  Information about its usage can be found here:\n",
    "(https://learn.microsoft.com/en-us/azure/cognitive-services/openai/reference#completions)\n",
    "The function defined below takes prompt and settings parameters sends the request to the endpoint and prints the text element from the result.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to send the prompt to the ChatGPT model\n",
    "# More info : https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/chatgpt?pivots=programming-language-chat-completions\n",
    "def send_prompt(prompt, temperature=0.5, top_p=0.5, max_tokens=32):\n",
    "    response = openai.Completion.create(\n",
    "        engine=chatgpt_model_name,\n",
    "        temperature=temperature,\n",
    "        prompt=prompt,\n",
    "        top_p=top_p,\n",
    "    )\n",
    "    print(\"----\")\n",
    "    print(\"Settings:\")\n",
    "    print(\"temperature: \"+ str(temperature) + \" top_p: \" + str(top_p) + \" max_tokens: \" + str(max_tokens))\n",
    "    print(\"Prompt: \" + prompt)\n",
    "    print(\"Response: \")\n",
    "    print(response['choices'][0]['text'])\n",
    "    print(\"----\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 Zero shot sentiment classification prompt examples\n",
    "This prompt works well because the LLM understands \"sentiment\", in the zero shot examples the prompt is self contained and does not "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt =  \"\"\"\n",
    "Text: I think the vacation is okay.\n",
    "Sentiment:\n",
    "\"\"\"\n",
    "send_prompt(prompt)\n",
    "\n",
    "prompt =  \"\"\"\n",
    "Text: I think the vacation is awesome.\n",
    "Sentiment:\n",
    "\"\"\"\n",
    "send_prompt(prompt)\n",
    "\n",
    "prompt =  \"\"\"\n",
    "Text: I think the vacation is awful.\n",
    "Sentiment:\n",
    "\"\"\"\n",
    "send_prompt(prompt)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 One shot sentiment classification prompt examples\n",
    "In this case the prompt provides one example of how the response should be formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt =  \"\"\"\n",
    "Text: I think the vacation is awsome\n",
    "Response: The user is feeling good about things\n",
    "Text: I think the vacation is so much fun.\n",
    "Response:\n",
    "\"\"\"\n",
    "response = send_prompt(prompt)\n",
    "\n",
    "print('Response: ', response)\n",
    "prompt =  \"\"\"\n",
    "Text: I think the vacation is awsome\n",
    "Response: The user is feeling good about things\n",
    "Text: I think the vacation is okay.\n",
    "Response:\n",
    "\"\"\"\n",
    "response = send_prompt(prompt)\n",
    "print('Response: ', response)\n",
    "\n",
    "prompt =  \"\"\"\n",
    "Text: I think the vacation is awsome\n",
    "Response: The user is feeling good about things\n",
    "Text: I think the vacation is awful.\n",
    "Response:\n",
    "\"\"\"\n",
    "response = send_prompt(prompt)\n",
    "print('Response: ', response)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0 Few shot sentiment classification prompt examples\n",
    "In these examples we will use few shot technique to change clssification of the text to respond with words other than positive, neutral, or negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt =  \"\"\"\n",
    "Text: Today the weather is fantastic\n",
    "Classification: Good\n",
    "Text: The furniture is small.\n",
    "Classification: Okay\n",
    "Text: The vacation was terrible\n",
    "Classification: Bad\n",
    "Text: The food was awesome\n",
    "Classification:\n",
    "\"\"\"\n",
    "response = send_prompt(prompt)\n",
    "print('Response: ', response)\n",
    "\n",
    "prompt =  \"\"\"\n",
    "Text: Today the weather is fantastic\n",
    "Classification: Good\n",
    "Text: The furniture is small.\n",
    "Classification: Okay\n",
    "Text: The vacation was terrible\n",
    "Classification: Bad\n",
    "Text: The food was warm\n",
    "Classification:\n",
    "\"\"\"\n",
    "response = send_prompt(prompt)\n",
    "print('Response: ', response)\n",
    "\n",
    "prompt =  \"\"\"\n",
    "Text: Today the weather is fantastic\n",
    "Classification: Good\n",
    "Text: The furniture is small.\n",
    "Classification: Okay\n",
    "Text: The vacation was terrible\n",
    "Classification: Bad\n",
    "Text: The food was terrible\n",
    "Classification:\n",
    "\"\"\"\n",
    "response = send_prompt(prompt)\n",
    "print('Response: ', response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "fc180f703c9255d3d630e6d09ed4eb3355d27845db546035ce1b410f2bfa43b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
