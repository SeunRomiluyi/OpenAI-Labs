{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aad9e597-a383-47e8-b6f4-663ca511b04b",
   "metadata": {},
   "source": [
    "# Example AML Deployment Notebook\n",
    "\n",
    "The following notebook provides an example for deploying an FFModel solution to an Azure Machine Learning (AML) Managed Endpoint. Executing this notebook will prepare an AML Managed Endpoint with an example FFModel Solution.\n",
    "\n",
    "In the cell below, we have an `solution_config_path` which is the path to an solution configuration yaml describing a single FFModel LLM-based solution that we'd like to deploy for inference. This solution will be run in the context of the FFModel environment configuration described in the file located at `enviornment_config_path`. We will also name the deployment `nl2python` as it is an inferencing solution for converting natural language prompts to python code.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2b273a-afda-4463-aee6-4c6261a0d26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "solution_config_path = \"./nl2python_solution.yaml\"\n",
    "environment_config_path = \"~/.ffmodel\"\n",
    "deployment_name = \"nl2python\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cd52e2-1c0e-4704-ae00-5f167dd0d5c7",
   "metadata": {},
   "source": [
    "The cell below triggers the actual deployment of the FFModel solution to the FFModel AML intance. We will create an AML Managed Endpoint called `FFModelSolutionEndpoint` and on it there will be a deployment named `nl2python` set to 100% of the traffic. The solution on this deployment will correspond to the solution config we provided for deployment. The deployment will be backed by a virtual machine with the SKU type `sku_type` (You can find a list of [available SKU types here](https://learn.microsoft.com/en-us/azure/machine-learning/reference-managed-online-endpoints-vm-sku-list). To see the SKU quota available on your FFModel AML instance, follow the [guidance here](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-manage-quotas#view-your-usage-and-quotas-in-the-azure-portal).).\n",
    "\n",
    "Note that this step will take a few minutes to execute and progress can be monitored here or in the AML Studio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef255330-963f-4efa-bd9d-d536f43546a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ffmodel.core.aml import deployment_orchestrator\n",
    "\n",
    "deployment_orchestrator.deploy_solution(\n",
    "    solution_config_path=solution_config_path,\n",
    "    environment_config_path=environment_config_path,\n",
    "    endpoint_name=\"FFModelSolutionEndpoint\",\n",
    "    deployment_name=deployment_name,\n",
    "    deployment_description=f\"Sample '{deployment_name}' deployment to FFModel Solution Endpoint\",\n",
    "    sku_type=\"Standard_DS1_v2\", # default: Standard_DS2_v2\n",
    "    traffic_volume=100, # First deployment must have 100% of traffic; future deployments can have traffic <= 100%\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc6507d-8305-4337-b0c3-d4138c0c0bf3",
   "metadata": {},
   "source": [
    "## Testing Your Deployed FFModel Solution\n",
    "\n",
    "To test your deployed solution, you can reference the Endpoint's \"Test\" tab in the AML Studio (more information [here](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-use-managed-online-endpoint-studio#test)). Alternatively, you can follow the \"Consume\" tab in the AML Studio and use the sample code there to test your deployed solution. The code in the next few cells is taken from the AML \"Consume\" tab and repurposed to generate a response to a simple \"hello world\" example request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f3590a-3efb-4b3a-8fc4-36ba531eb4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Endpoint Url\n",
    "url = 'https://ffmodelsolutionendpoint.southcentralus.inference.ml.azure.com/score'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7f0be3-7ce6-462f-a020-5a923eb9c883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace this with the primary/secondary key or AMLToken for the endpoint\n",
    "api_key = '<API-KEY>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207b8259-cbf8-4cbc-8387-287cef4f1d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample \"Hello World\" Request Data\n",
    "request_data = {\n",
    "    \"user_nl\": \"print 'hello world' to the console\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df60793-a96e-4cf6-9e04-50025ef0a212",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import json\n",
    "import os\n",
    "import ssl\n",
    "\n",
    "def allowSelfSignedHttps(allowed):\n",
    "    # bypass the server certificate verification on client side\n",
    "    if allowed and not os.environ.get('PYTHONHTTPSVERIFY', '') and getattr(ssl, '_create_unverified_context', None):\n",
    "        ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "allowSelfSignedHttps(True) # this line is needed if you use self-signed certificate in your scoring service.\n",
    "\n",
    "body = str.encode(json.dumps(request_data))\n",
    "\n",
    "if not api_key:\n",
    "    raise Exception(\"A key should be provided to invoke the endpoint\")\n",
    "\n",
    "# The azureml-model-deployment header will force the request to go to a specific deployment.\n",
    "# Remove this header to have the request observe the endpoint traffic rules\n",
    "headers = {\n",
    "    'Content-Type':'application/json', 'Authorization':('Bearer '+ api_key),\n",
    "    'azureml-model-deployment': deployment_name\n",
    "}\n",
    "\n",
    "req = urllib.request.Request(url, body, headers)\n",
    "\n",
    "try:\n",
    "    response = urllib.request.urlopen(req)\n",
    "    result = response.read().decode(\"utf8\", \"ignore\")\n",
    "    print(result)\n",
    "except urllib.error.HTTPError as error:\n",
    "    # Print the headers - they include the request ID and the timestamp, which are useful for debugging the failure\n",
    "    print(\"The request failed with status code: \" + str(error.code))\n",
    "    print(error.info())\n",
    "    print(error.read().decode(\"utf8\", 'ignore'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
