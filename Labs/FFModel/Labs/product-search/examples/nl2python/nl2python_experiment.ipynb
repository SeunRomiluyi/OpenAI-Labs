{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f47999d6-e587-4fed-b9f7-ff464f057bbf",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Experimenting with Python\n",
    "\n",
    "This notebook provides a light example for running an experiment for a natural language to Python scenario. The experiment passes a dataset through some sample components that each serves a different part of the process and updates the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df4ec72-f004-47ae-a67a-fdcaabb02e61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "import traceback\n",
    "from ffmodel.core import orchestrator"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8f6d3c8a-fc41-47c9-a042-b403beae0e2c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Configs\n",
    "\n",
    "This section captures the experimentation configs.\n",
    "\n",
    "- `experiment_name`: the name of this experiment\n",
    "- `solution_config`: the path to an solution configuration yaml file describing a solution that we'd like to experiment with\n",
    "- `environment_config_path`: the path to an environment configuration yaml. Follow the instructions captured [here](../../docs/guides/environment_configs.md)\n",
    "- `experiment_output_path`: the path to store the output from the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123fc851-df51-43b9-90f0-201e1ae9cc4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "experiment_name = \"nl2python\"\n",
    "solution_config_path = \"./nl2python_solution.yaml\"\n",
    "environment_config_path = \"~/.ffmodel\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fa18a9af",
   "metadata": {},
   "source": [
    "## Setup few shot bank\n",
    "\n",
    "This experiment makes use of the `few_shot_embedding` pre-processor.\n",
    "This component looks at a set of example input, output pairs and picks the ones that should be most relevant.\n",
    "The selection is done based on the similarity between embeddings of the inputs.\n",
    "\n",
    "The input to this component is a few shot file, which is a pickle file that contains that input, output pairs, as well as a pre-computed embedding for each input.\n",
    "This way, at inference time only the embedding for the new input needs to be calculated.\n",
    "\n",
    "The `few_shot_embedding` component contains a static method for helping create the few shot file.\n",
    "In this example, the source input file can be found in `sample_datasets/nl2python_fewshot_dataset.jsonl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f103e071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the path for the top level root to enable components import\n",
    "sys.path.insert(0, \"../..\")\n",
    "\n",
    "if not os.path.exists(\"sample_datasets/nl2python_fewshot_dataset_text-embedding-ada-002.pkl\"):\n",
    "    from ffmodel.core.environment_config import EnvironmentConfigs\n",
    "    from components.pre_processors.few_shot_embedding import Component\n",
    "\n",
    "    EnvironmentConfigs.initialize(environment_config_path)\n",
    "    Component.create_few_shot_file(\"sample_datasets/nl2python_fewshot_dataset.jsonl\", \"text-embedding-ada-002\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1e01ff9e-6de8-4b98-ab8e-b49563adb11a",
   "metadata": {},
   "source": [
    "## Execute Local Experiment\n",
    "\n",
    "With the solution config, environment config, and evaluation dataset defined, we can now run an experiment. In this notebook, we're running an experiment on your local machine. FFModel will refer to Azure Machine Learning to fetch the evaluation dataset we prepared previously, but all remaining steps (besides the inference on Azure OpenAI in the model caller step) will run in the context of your local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6753da-bf60-48bb-9392-41fb16fb9c5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ffmodel.core import orchestrator\n",
    "\n",
    "data_models = orchestrator.execute_experiment_on_local(\n",
    "    solution_config_path, environment_config_path\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b1f5c767-4803-48b3-9e11-e87c07c3d486",
   "metadata": {},
   "source": [
    "## Analyze Experiment Results\n",
    "\n",
    "With the experiment complete, we can now analyze the results. FFModel experiments run on data models, which hold the state of any given experiment request as it runs through the solution defined by the solution config. We can analyze the result in our data models below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b305697-6e6b-4d87-afa2-408976c7b761",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Number of data models returned: {len(data_models)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175c3696-b9b4-447c-8782-f86a22af3fe3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(data_models[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "74b5fd69-050a-4d29-ad56-46deb3b4b3ba",
   "metadata": {},
   "source": [
    "Since our solution configuration included a writer component, we can also retrieve the aggregated experiment results across all the data models. For local experiments, outputs get written locally to the path designated in the solution config (note that the path is appended with a date-time stamp to differentiate between different runs). An example output path is included in the cell below and visualized as a data frame of results (note: ignore any AttributeErrors that might be thrown):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b64eb3-4dd0-4674-9f72-82a8abfb4f40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Update the Writer Output Path with the most-recently written file in\n",
    "# Note: Update the file name with the name of your output file\n",
    "experiment_results_output_path = (\n",
    "    \"outputs/nl2python_experiment_results-20230613-180911.jsonl\"\n",
    ")\n",
    "\n",
    "# Display experiment results\n",
    "experiment_results = pd.read_json(experiment_results_output_path, lines=True)\n",
    "experiment_results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "943cbd8f",
   "metadata": {},
   "source": [
    "## Deployment\n",
    "\n",
    "If you are happy with the performance of the solution, continue to [`ExampleDeploymentAML.ipynb`](./ExampleDeploymentAML.ipynb) to create a managed endpoint hosting the solution for external consumption."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "7d1fcbe86da292cde128d7ed540e59eb792ee3fbad5193d54f613609246e8fb1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
