{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimenting with SQL\n",
    "\n",
    "This notebook provides a light example for running an experiment for a natural language to SQL scenario.\n",
    "\n",
    "## The Experiment\n",
    "\n",
    "This experiment is simple, it appends static context to guide the LLM to generate SQL code from the NL prompt.\n",
    "This can be seen in the [solution config file](./solution_configs/nl2sql_config.yaml).\n",
    "It then calls the LLM and retrieves the first completion as output.\n",
    "\n",
    "## Running on Azure ML vs Local\n",
    "\n",
    "The current implementation runs the experiment on an Azure Machine Learning (AML) Workspace,\n",
    "if you want to run this experiment locally, you need to create a new notebook using the [existing notebook template](../../experiments/templates/run_experiments_template.ipynb).\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- You need to have the `sqlglot` package installed to run this experiment.\n",
    "- You need to have an Azure subscription with an AML workspace.\n",
    "- You need to have access to an OpenAI service.\n",
    "- By default, this experiment uses the `code-davinci-002` model from OpenAI. If you do not have this model, please update the [solution config file](./solution_configs/nl2sql_config.yaml) to use the model you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import traceback\n",
    "from ffmodel.core import orchestrator\n",
    "from ffmodel.core.aml import aml_orchestrator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing `sqlglot`\n",
    "\n",
    "Before running this experiment, you need to install the `sqlglot` package if you\n",
    "haven't already. Also, we're going to make a `requirements.txt` file for use\n",
    "by AML to track the dependencies of this experiment.\n",
    "\n",
    "First, let's create (or update) the `requirements.txt` file at the root of our\n",
    "project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_requirements():\n",
    "    path = \"../../requirements.txt\"\n",
    "    requirements = \"\\n\".join(\n",
    "        [\n",
    "            \"# The following requirement is used by the nl2sql example:\",\n",
    "            \"sqlglot~=11.5.8\",\n",
    "            \"\",  # Add a new line\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Create requirements.txt if needed\n",
    "    if not os.path.exists(\"../../requirements.txt\"):\n",
    "        # Add sqlglot to requirements.txt\n",
    "        with open(\"../../requirements.txt\", \"w\") as f:\n",
    "            f.write(requirements)\n",
    "    else:\n",
    "        # Check if sqlglot is in requirements.txt\n",
    "        with open(\"../../requirements.txt\", \"r\") as f:\n",
    "            missing = not \"sqlglot\" in f.read()\n",
    "\n",
    "        # Add sqlglot to requirements.txt\n",
    "        if missing:\n",
    "            with open(\"../../requirements.txt\", \"a\") as f:\n",
    "                f.write(f\"\\n{requirements}\")\n",
    "\n",
    "\n",
    "prepare_requirements()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's install our dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r ../../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configs\n",
    "\n",
    "This section captures the experimentation configs.\n",
    "\n",
    "- `experiment_name`: the name of this experiment\n",
    "- `solution_configs`: an array that holds the paths to the solution configuration yaml files describing solutions that we'd like to experiment with\n",
    "- `environment_config_path`: the path to an environment configuration yaml. Follow the instructions captured [here](../../docs/guides/environment_configs.md).\n",
    "- `experiment_output_path`: the path to store the output from all experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"nl2sql\"\n",
    "solution_configs = [\"solution_configs/nl2sql_config.yaml\"]\n",
    "environment_config_path = \"~/.ffmodel\"\n",
    "experiment_output_path = os.path.join(\"outputs\", experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions\n",
    "\n",
    "Using the FFModel orchestrator to run the experiment on AzureML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ffmodel_experiment(solution_config_path):\n",
    "    \"\"\"\n",
    "    Function that runs an FFModel experiments within AML. The resulting job name will be mapped to it's\n",
    "    corresponding exp config file and will be returned as output\n",
    "    \"\"\"\n",
    "    global aml_jobs\n",
    "\n",
    "    print(f\"Executing solution config file {solution_config_path}\")\n",
    "    print(\"----------------------------------------------\")\n",
    "\n",
    "    # execute experiment\n",
    "    aml_job_name = orchestrator.execute_experiment_on_aml(solution_config_path, environment_config_path)\n",
    "\n",
    "    print(f\"Solution config {solution_config_path} - with job name {aml_job_name}\")\n",
    "    aml_jobs[aml_job_name] = {\"solution_config\": solution_config_path}\n",
    "\n",
    "\n",
    "def get_data_models(aml_jobs: dict) -> dict:\n",
    "    \"\"\"\n",
    "    This function waits until all experiments finished executing and then downloads their outputs.\n",
    "    \"\"\"\n",
    "    for aml_job_name in aml_jobs:\n",
    "        # wait for the experiment to finish running\n",
    "        aml_orchestrator.wait_for_completion(aml_job_name)\n",
    "        # retrieve data model once the job is completed\n",
    "        data_models = aml_orchestrator.retrieve_final_data_models(aml_job_name)\n",
    "        aml_jobs[aml_job_name][\"data_models\"] = data_models\n",
    "\n",
    "    return aml_jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentation\n",
    "\n",
    "Run the experiments and capture their outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "aml_jobs = {}\n",
    "aml_job_outputs = {}\n",
    "\n",
    "# ensure the outputs path exists before running any experiment\n",
    "Path(experiment_output_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Running the following experiments: \\n {str(solution_configs)}\")\n",
    "try:\n",
    "    for exp in solution_configs:\n",
    "        run_ffmodel_experiment(exp)\n",
    "except:\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the experiment outputs\n",
    "\n",
    "Both experiment pipelines are running on AML. At this time, we need to wait for them to finish executing before we can compare the experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aml_jobs = get_data_models(aml_jobs)\n",
    "\n",
    "for job in aml_jobs:\n",
    "    output_path = os.path.basename(aml_jobs[job][\"solution_config\"])\n",
    "    output_path = os.path.splitext(output_path)[0]\n",
    "    output_path = f\"{os.path.join(experiment_output_path, output_path)}.jsonl\"\n",
    "    with open(output_path, \"w\") as f:\n",
    "        f.write(\"\\n\".join(json.dumps(item.to_dict()) for item in aml_jobs[job][\"data_models\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
